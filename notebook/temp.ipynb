{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In[23]:\n",
    "#Load certain variables:\n",
    "values_dir = repo.joinpath('data/values_for_distributions')\n",
    "rech_farm = load_obj(values_dir,'rech_rng_farm')\n",
    "rech_precip_sum,rech_precip_wint = load_obj(values_dir,'rech_rng_precip')\n",
    "ghb_inland_sum,ghb_inland_wint = load_obj(values_dir,'ghb_rng_model_edge')\n",
    "wel_rng_mpday = load_obj(values_dir,'wel_rng_mday')\n",
    "wel_rng_m3pday = np.r_[wel_rng_mpday]*np.prod(farm_size)\n",
    "\n",
    "from scipy.io import savemat,loadmat\n",
    "import datetime\n",
    "\n",
    "def run_MC(tot_it,plotyn=False,silent=True):\n",
    "    #### MAKE NEW/ADD TO OLD EXPT ####\n",
    "    check_MC_inputParams()\n",
    "    runlog = []\n",
    "    #### VARY PARAMS ####\n",
    "    it = 0\n",
    "    while it < tot_it:\n",
    "        ssm_data = {}\n",
    "        it += 1\n",
    "\n",
    "        #Make timestamp\n",
    "        sep = ''\n",
    "        ts = datetime.datetime.now().strftime('%m'+sep+'%d'+sep+'%H'+sep+'%M'+sep+'%S')\n",
    "\n",
    "        #head_inland_sum\n",
    "        dist_inland = 10000 #m\n",
    "        low,high = np.r_[ghb_inland_sum]/dist_inland*Lx #ghb values taken from NMGWM, apply same gradient to this model\n",
    "        low,high = np.r_[-1.1,0] #adjusted from ghb values because model didnt converge for larger values\n",
    "        parname='head_inland_sum'\n",
    "        val = sample_dist(sts.uniform,1,*(low,high-low))\n",
    "        add_to_paramdict(m.inputParams,parname,val)\n",
    "        head_inland_sum = val\n",
    "\n",
    "        #head_inland_wint\n",
    "        low,high = np.r_[ghb_inland_wint]/dist_inland*Lx #ghb values taken from NMGWM, apply same gradient to this model\n",
    "        low,high = np.r_[0,3] #ghb values taken from NMGWM, apply same gradient to this model\n",
    "        parname='head_inland_wint'\n",
    "        val = sample_dist(sts.uniform,1,*(low,high-low))\n",
    "        add_to_paramdict(m.inputParams,parname,val)\n",
    "        head_inland_wint = val\n",
    "\n",
    "        #set ghb data and create dicts\n",
    "        chd_data, ssm_data_base, ghb_data, wel_data_base = make_bc_dicts((head_inland_sum,head_inland_wint))\n",
    "        save_obj(m.MC_file.parent,wel_data_base,'wel_data_base')\n",
    "        save_obj(m.MC_file.parent,ssm_data_base,'ssm_data_base')\n",
    "\n",
    "        if heterogenous==0:\n",
    "        #HOMOGENOUS ONLY\n",
    "            #hk\n",
    "            low,high= (-0.5,2)\n",
    "            parname='hk'\n",
    "            val = sample_dist(sts.uniform,1,*(low,high-low))\n",
    "            add_to_paramdict(m.inputParams,parname,val)\n",
    "            hk = np.ones((nlay,nrow,ncol))* (10**val)\n",
    "            \n",
    "            ##por: porosity\n",
    "            #      \n",
    "            low,high = np.r_[.2,.5]\n",
    "            parname='por'\n",
    "            val = sample_dist(sts.uniform,1,*(low,high-low))\n",
    "            add_to_paramdict(m.inputParams,parname,val)\n",
    "            por = val\n",
    "\n",
    "        elif heterogenous in [1,2]:\n",
    "            #########HETEROGENOUS ONLY ##############\n",
    "            ##por: porosity\n",
    "            #\n",
    "            low,high = np.r_[.2,.5]\n",
    "            parname='por1'\n",
    "            val = sample_dist(sts.uniform,1,*(low,high-low))\n",
    "            add_to_paramdict(m.inputParams,parname,val)\n",
    "            por1 = val\n",
    "            \n",
    "            ##por: porosity\n",
    "            #\n",
    "            low,high = np.r_[.3,.7]\n",
    "            parname='por2'\n",
    "            val = sample_dist(sts.uniform,1,*(low,high-low))\n",
    "            add_to_paramdict(m.inputParams,parname,val)\n",
    "            por2 = val\n",
    "            \n",
    "            #hk1\n",
    "            low= -2\n",
    "            high = 0\n",
    "            parname='hk1'\n",
    "            val = sample_dist(sts.uniform,1,*(low,high-low))\n",
    "            add_to_paramdict(m.inputParams,parname,val)\n",
    "            hk1 = 10**val\n",
    "\n",
    "            #hk2\n",
    "            low= 0\n",
    "            high = 2\n",
    "            parname='hk2'\n",
    "            val = sample_dist(sts.uniform,1,*(low,high-low))\n",
    "            add_to_paramdict(m.inputParams,parname,val)\n",
    "            hk2 = 10**val\n",
    "\n",
    "            #lith_prop\n",
    "            low= 0\n",
    "            high = 0.5\n",
    "            parname='lith_prop'\n",
    "            val = sample_dist(sts.uniform,1,*(low,high-low))\n",
    "            add_to_paramdict(m.inputParams,parname,val)\n",
    "            lith_prop = round(val,2)\n",
    "\n",
    "            if heterogenous==1:\n",
    "                #vario_type\n",
    "                parname='vario_type'\n",
    "                val = int(round(np.random.rand()))\n",
    "                add_to_paramdict(m.inputParams,parname,val)\n",
    "                if val==1:\n",
    "                    vario_type = 'Gaussian'\n",
    "                elif val==0:\n",
    "                    vario_type = 'Exponential'\n",
    "                else:\n",
    "                    pass\n",
    "\n",
    "                #corr_len\n",
    "                low= 250\n",
    "                high = 1000\n",
    "                parname='corr_len'\n",
    "                val = sample_dist(sts.uniform,1,*(low,high-low))\n",
    "                add_to_paramdict(m.inputParams,parname,val)\n",
    "                corr_len = val\n",
    "\n",
    "                #corr_len_zx\n",
    "                # equal to lz/lx\n",
    "                low= .01\n",
    "                high = .1\n",
    "                parname='corr_len_zx'\n",
    "                val = sample_dist(sts.uniform,1,*(low,high-low))\n",
    "                add_to_paramdict(m.inputParams,parname,val)\n",
    "                corr_len_zx = val\n",
    "\n",
    "                #corr_len_yx\n",
    "                # equal to ly/lx\n",
    "                low= 0.1\n",
    "                high = 1\n",
    "                parname='corr_len_yx'\n",
    "                val = sample_dist(sts.uniform,1,*(low,high-low))\n",
    "                add_to_paramdict(m.inputParams,parname,val)\n",
    "                corr_len_yx = val\n",
    "\n",
    "                #clay_lyr_yn\n",
    "                parname='clay_lyr_yn'\n",
    "                val = sample_dist(sts.binom,1,*(1,.5))\n",
    "                add_to_paramdict(m.inputParams,parname,val)\n",
    "                clay_lyr_yn = bool(val)\n",
    "\n",
    "                #Create hk grid\n",
    "                mu = np.log(hkSand)\n",
    "                sill = 1\n",
    "                lcol = int(corr_len/delr)\n",
    "                llay = int(corr_len*corr_len_zx/np.mean(delv))\n",
    "                lrow = int(corr_len*corr_len_yx/delc)\n",
    "                fft_grid = np.exp(simulationFFT.simulFFT(nrow, nlay, ncol, mu, sill, vario_type, lrow , llay, lcol))\n",
    "                grid = np.log10(fft_grid)\n",
    "                lith_props = [lith_prop,1-lith_prop]\n",
    "                hk_vals = [hk1,hk2]\n",
    "                hk = truncate_grf(grid,lith_props,hk_vals,log10trans=False,plotyn=plotyn)\n",
    "                if clay_lyr_yn:\n",
    "                    lyr_ind = np.where((henry_botm<-2) & (henry_botm >-15))\n",
    "                    hk[lyr_ind,:,:int(ncol*3/4)] = hk_vals[0]\n",
    "\n",
    "            elif heterogenous==2: #MPS\n",
    "                import sgs_mod\n",
    "                nodes = 25\n",
    "                search_ellipse=(2000,500,20,0,0,0) #(max,med,min,az,dip,rake)\n",
    "                grid_size = (Lz,Ly,Lx)\n",
    "                grid_cells = dim\n",
    "                rotind= [1,2,0] #simulation in a Y,X,Z grid\n",
    "                constrain=1\n",
    "                seed = np.random.randint(0,10000)\n",
    "                expgridfile,outgrid,rotind,grid_cells_sgems = sgs_mod.snesim_grid(m.name, Path(model_ws),\n",
    "                                                                                  grid_size,grid_cells,search_ellipse=search_ellipse,\n",
    "                                                                                  TIfile=None,TIname=None,marg=1-lith_prop,seed=1,nodes=nodes,\n",
    "                                                                                  nreals=1,output=False,rmfiles=False,rotind=rotind,constrain=constrain)\n",
    "                outgrid = sgs_mod.read_sgems_grid(expgridfile,grid_cells,grid_cells_sgems)\n",
    "                outgrid = outgrid.squeeze()\n",
    "                hk = np.zeros(dim,dtype=np.float)\n",
    "                hk[np.where(outgrid==0)]=hk1\n",
    "#                 hk[np.where(outgrid==1)]=hk2\n",
    "            \n",
    "            hk1_ind = np.where(hk==hk.max())\n",
    "            hk2_ind = np.where(hk==hk.min())\n",
    "            por = np.ones((nlay,nrow,ncol),dtype=np.float)\n",
    "            por[hk1_ind] = por1\n",
    "            por[hk2_ind] = por2\n",
    "            hk[wel_cells] = hk.max()\n",
    "            np.save(m.MC_file.parent.joinpath('hk'+ts+'.npy'),hk)\n",
    "\n",
    "        ####### END OF HETEROGENOUS BLOCK ############\n",
    "\n",
    "        ##vka: ratio of vk/hk\n",
    "        #      Uniform (1/20,1)\n",
    "        low= 1/20\n",
    "        high = 1\n",
    "        parname='vka'\n",
    "        val = sample_dist(sts.uniform,1,*(low,high-low))\n",
    "        add_to_paramdict(m.inputParams,parname,val)\n",
    "        vka = val\n",
    "\n",
    "        ##al: #longitudinal dispersivity (m)\n",
    "        #      Uniform [0.1,20] #10 from Walther et al\n",
    "        low= 0.1\n",
    "        high = 10\n",
    "        parname='al'\n",
    "        val = sample_dist(sts.uniform,1,*(low,high-low))\n",
    "        add_to_paramdict(m.inputParams,parname,val)\n",
    "        al = val\n",
    "\n",
    "        ##dmcoef: #dispersion coefficient (m2/day)\n",
    "        #      log-uniform [1e-10,1e-5] #2e-9 from Walther et al\n",
    "        low,high = np.log10([1e-10,1e-5])\n",
    "        parname='dmcoef'\n",
    "        val = sample_dist(sts.uniform,1,*(low,high-low))\n",
    "        add_to_paramdict(m.inputParams,parname,val)\n",
    "        dmcoef = 10**val\n",
    "\n",
    "        ##sy: #specific yield\n",
    "        #      \n",
    "        low,high = np.r_[.1,.4]\n",
    "        parname='sy'\n",
    "        val = sample_dist(sts.uniform,1,*(low,high-low))\n",
    "        add_to_paramdict(m.inputParams,parname,val)\n",
    "        sy = val\n",
    "\n",
    "        ##ss: specific storage\n",
    "        #      \n",
    "        low,high = np.log10([5.0e-5,5.0e-3])\n",
    "        parname='ss'\n",
    "        val = sample_dist(sts.uniform,1,*(low,high-low))\n",
    "        add_to_paramdict(m.inputParams,parname,val)\n",
    "        ss = 10**val\n",
    "\n",
    "\n",
    "        ##wel\n",
    "        pressure_size = 25*8*2.59e+6 #area of pressure subarea mi*mi*(m2/mi)\n",
    "        pump_rate_m3perm2 = 118000*1233.48/(pressure_size) #(af/y)*(af/m3)/(m2)\n",
    "\n",
    "        low,high = np.log10((1e2,1e5))\n",
    "        low,high = np.log10((1e2,1e3))\n",
    "        parname='wel'\n",
    "        val = sample_dist(sts.uniform,n_wells,*(low,high-low))\n",
    "        wel_flux = val\n",
    "        for i in range(n_wells):\n",
    "            parname_temp = parname+str(i)\n",
    "            add_to_paramdict(m.inputParams,parname_temp,wel_flux[i])\n",
    "\n",
    "        #write wel data\n",
    "        ssm_data_base = load_obj(m.MC_file.parent,'ssm_data_base')\n",
    "        wel_data_base = load_obj(m.MC_file.parent,'wel_data_base')\n",
    "        wel_data,ssm_data,_ = add_pumping_wells(wel_data_base,ssm_data_base,n_wells,wel_flux,farm_orig,kper_odd)\n",
    "\n",
    "        ##rech_precip\n",
    "        low,high = np.log10([1e-4,5e-1])\n",
    "        val = sample_dist(sts.uniform,1,*(low,high-low))\n",
    "        parname='rech_precip'\n",
    "        add_to_paramdict(m.inputParams,parname,val)\n",
    "        rech_precip = 10**val/(nrow*ncol)\n",
    "\n",
    "        #rech_farm\n",
    "        low,high = [0.05,0.2] #percentage of the well extraction\n",
    "        val = sample_dist(sts.uniform,1,*(low,high-low))\n",
    "        parname='rech_farm'\n",
    "        add_to_paramdict(m.inputParams,parname,val)\n",
    "        rech_farm = [val*flux/np.prod(farm_size) for flux in wel_flux]\n",
    "\n",
    "        #Assign recharge data\n",
    "        rech_farm_mat = np.zeros((nrow,ncol),dtype=np.float32)\n",
    "        for i in range(nfarms):\n",
    "            rech_farm_mat[farm_loc_list[i]] = rech_farm[i]\n",
    "\n",
    "        rech_data = {}\n",
    "        for i in range(len(perlen)):\n",
    "            if i in kper_even:\n",
    "                rech_data[i] = rech_precip\n",
    "            elif i in kper_odd:\n",
    "                rech_data[i] = rech_farm_mat\n",
    "\n",
    "        ##riv_stg\n",
    "        low,high = (.5,1.5)\n",
    "        val = sample_dist(sts.uniform,1,*(low,high-low))\n",
    "        parname='riv_stg'\n",
    "        add_to_paramdict(m.inputParams,parname,val)\n",
    "        riv_stg = val\n",
    "\n",
    "        ##riv_cond\n",
    "        low,high = np.log10((.001,10))\n",
    "        val = sample_dist(sts.uniform,1,*(low,high-low))\n",
    "        parname='riv_cond'\n",
    "        add_to_paramdict(m.inputParams,parname,val)\n",
    "        riv_cond = val\n",
    "\n",
    "        #Write river data--take SSM data from WEL!!\n",
    "        riv_grad = .0005\n",
    "        '''\n",
    "        measurements from Google Earth show 7 ft drop over 8 mi = avg .0001 avg gradient\n",
    "        Google Earth imagery shows that at least some patches of the river stay wet year-round (Oct 19,2016)\n",
    "        This most likely means that this is a gaining river, at least during the summer.\n",
    "        \n",
    "        '''\n",
    "        \n",
    "        riv_data,ssm_data = write_river_data(riv_loc,stage,cond,riv_grad,kper_even,ssm_data)\n",
    "\n",
    "        #Create instances in flopy\n",
    "        bas = flopy.modflow.ModflowBas(m, ibound, strt=strt)\n",
    "        if bc_ocean=='CHD' or bc_inland=='CHD' :\n",
    "            chd = flopy.modflow.ModflowChd(m, stress_period_data=chd_data)\n",
    "        if bc_ocean=='GHB' or bc_inland=='GHB'or bc_right_edge=='GHB':\n",
    "            ghb = flopy.modflow.ModflowGhb(m, stress_period_data=ghb_data)\n",
    "\n",
    "        rch = flopy.modflow.ModflowRch(m, rech=rech_data)\n",
    "        wel = flopy.modflow.ModflowWel(m, stress_period_data=wel_data, ipakcb=ipakcb)\n",
    "        riv = flopy.modflow.ModflowRiv(m, stress_period_data=riv_data)\n",
    "        # Add LPF package to the MODFLOW model\n",
    "        lpf = flopy.modflow.ModflowLpf(m, hk=hk, vka=vka, ipakcb=ipakcb,laytyp=1,laywet=1,\n",
    "                                      ss=ss,sy=sy)\n",
    "\n",
    "        # Add PCG Package to the MODFLOW model\n",
    "        pcg = flopy.modflow.ModflowPcg(m, hclose=1.0e-8)\n",
    "\n",
    "        # Add OC package to the MODFLOW model\n",
    "        oc = flopy.modflow.ModflowOc(m,\n",
    "                                     stress_period_data=oc_data,\n",
    "                                     compact=True)\n",
    "\n",
    "        #Create the basic MT3DMS model structure\n",
    "        btn = flopy.mt3d.Mt3dBtn(m,\n",
    "                                 laycon=lpf.laytyp, htop=henry_top,\n",
    "                                 dz=dis.thickness.get_value(), prsity=por, icbund=icbund,\n",
    "                                 sconc=sconc, nprs=1,timprs=timprs)\n",
    "        adv = flopy.mt3d.Mt3dAdv(m, mixelm=-1)\n",
    "        dsp = flopy.mt3d.Mt3dDsp(m, al=al, dmcoef=dmcoef)\n",
    "        gcg = flopy.mt3d.Mt3dGcg(m, iter1=50, mxiter=1, isolve=1, cclose=1e-5)\n",
    "        ssm = flopy.mt3d.Mt3dSsm(m, stress_period_data=ssm_data)\n",
    "\n",
    "        #vdf = flopy.seawat.SeawatVdf(m, iwtable=0, densemin=0, densemax=0,denseref=1000., denseslp=0.7143, firstdt=1e-3)\n",
    "        vdf = flopy.seawat.SeawatVdf(m, mtdnconc=1, mfnadvfd=1, nswtcpl=0, iwtable=1,\n",
    "                                     densemin=0., densemax=0., denseslp=denseslp, denseref=densefresh)\n",
    "\n",
    "        #Write input\n",
    "        m.write_input()\n",
    "\n",
    "        # Try to delete the output files, to prevent accidental use of older files\n",
    "        flist = [os.path.join(model_ws,'MT3D.CNF'),\n",
    "                  os.path.join(model_ws,'MT3D001.MAS'),\n",
    "                  os.path.join(model_ws, modelname + '.hds'),\n",
    "                  os.path.join(model_ws, 'MT3D001.UCN'),\n",
    "                  os.path.join(model_ws, 'MT3D001.UCN'),\n",
    "                  os.path.join(model_ws, modelname + '.cbc')]\n",
    "        for f in flist:\n",
    "            try:\n",
    "                os.remove(f)\n",
    "            except:\n",
    "                print('did not find file to remove: {}'.format(f))\n",
    "\n",
    "\n",
    "        if plotyn:\n",
    "            m.plot_hk_ibound(rowslice=rowslice,gridon=gridon)\n",
    "        #Run model\n",
    "        print('Running iteration {} of {}...'.format(it,tot_it))\n",
    "        v = m.run_model(silent=silent, report=True)\n",
    "        for idx in range(-3, 0):\n",
    "            print(v[1][idx])\n",
    "        runlog.append(v[0])\n",
    "        if v[0]:\n",
    "            #Record final salinity as .npy, also move full CBC and UCN files to expt folder\n",
    "            _ = record_salinity(m,ts_hms=ts);\n",
    "            copy_rename(os.path.join(m.model_ws,'MT3D001.UCN'),m.MC_file.parent.joinpath('conc_'+ts+'.UCN').as_posix())\n",
    "            #copy_rename(os.path.join(m.model_ws,m.name+'.cbc'),m.MC_file.parent.joinpath('cbc_'+ts_hms+'.cbc').as_posix())\n",
    "            print('Finished iteration {} of {} successfully...\\n\\n\\n\\n'.format(it,tot_it))\n",
    "        else:\n",
    "            print('Unsuccessful iteration {} of {}, deleting inputParams from this it...\\n\\n\\n\\n'.format(it,tot_it))\n",
    "            #m.inputParams = rem_last_ind_from_dict(m.inputParams)\n",
    "    inputParams_success,inputParams_fail = filt_inds_from_dict(m.inputParams,np.arange(len(runlog))[runlog])\n",
    "    inputParams_all = m.inputParams\n",
    "    inputParams = {'inputParams_all':inputParams_all,\n",
    "                   'inputParams_success': inputParams_success,\n",
    "                   'inputParams_fail': inputParams_fail,\n",
    "                   'runlog':runlog}\n",
    "    #Save inputParams immediately to prevent accidental destruction of them\n",
    "    savemat(m.MC_file.parent.joinpath('inputParams.mat').as_posix(),inputParams)\n",
    "    np.save(m.MC_file.parent.joinpath('inputParams_all.npy'),m.inputParams)\n",
    "    np.save(m.MC_file.parent.joinpath('runlog.npy'),runlog)\n",
    "    save_obj(m.MC_file.parent,m.inputParams,'inputParams_all')\n",
    "    save_obj(m.MC_file.parent,inputParams_success,'inputParams_success')\n",
    "    save_obj(m.MC_file.parent,m.dis.get_node_coordinates(),'yxz')\n",
    "    return m.inputParams,ssm_data,runlog\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
